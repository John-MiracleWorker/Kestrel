# ğŸ•Šï¸ Libre Bird

**Free, offline, privacy-first AI assistant for macOS** â€” a local alternative to [Little Bird](https://littlebird.ai).

All AI processing runs on your Mac using quantized open-source models. **Zero cloud. Zero cost. Zero data leaves your device.**

---

## âœ¨ Features

| Feature | Description |
|---|---|
| ğŸ’¬ **AI Chat** | Context-aware conversations powered by local LLMs |
| ğŸ‘ **Screen Context** | Reads your active window to provide relevant assistance |
| ğŸ““ **Daily Journal** | Auto-generates activity summaries from your screen context |
| âœ… **Task Manager** | AI-extracted tasks + manual task tracking |
| ğŸ”’ **100% Private** | All data stored locally in SQLite. No network requests. |
| ğŸš€ **Fast** | GPT-OSS 20B MoE: only 3.6B active params, runs on 16GB Macs |

## ğŸ§  Supported Models

| Model | Type | RAM (Q4) | Best For |
|---|---|---|---|
| **GPT-OSS 20B** | MoE (3.6B active) | ~12GB | Speed + quality (recommended) |
| **Qwen 3 14B** | Dense | ~10GB | Thinking mode, reasoning |

Any GGUF model works â€” just drop it in the `models/` directory.

## ğŸš€ Quick Start

### 1. Setup (one time)
```bash
chmod +x setup.sh start.sh
./setup.sh
```

This will:
- Create a Python virtual environment
- Install Python dependencies (with Metal GPU acceleration)
- Install frontend dependencies
- Optionally download the GPT-OSS 20B Q4 model

### 2. Start
```bash
./start.sh
```

Open **http://localhost:5173** in your browser.

### 3. Grant Accessibility Permissions
For screen context awareness:
1. Open **System Settings** â†’ **Privacy & Security** â†’ **Accessibility**
2. Add your terminal app (Terminal, iTerm2, Warp, etc.)

## ğŸ“ Project Structure

```
libre-bird/
â”œâ”€â”€ server.py              # FastAPI backend
â”œâ”€â”€ llm_engine.py          # LLM inference engine (llama-cpp-python)
â”œâ”€â”€ context_collector.py   # macOS screen context reader
â”œâ”€â”€ database.py            # SQLite storage with FTS5
â”œâ”€â”€ requirements.txt       # Python dependencies
â”œâ”€â”€ setup.sh               # One-command setup
â”œâ”€â”€ start.sh               # Launch both servers
â”œâ”€â”€ models/                # Place GGUF model files here
â”œâ”€â”€ libre_bird.db          # Local database (created on first run)
â””â”€â”€ frontend/
    â”œâ”€â”€ index.html         # App shell
    â”œâ”€â”€ index.css          # Dark glassmorphism design system
    â”œâ”€â”€ main.js            # Application logic
    â”œâ”€â”€ package.json       # Vite config
    â””â”€â”€ vite.config.js     # Dev server config
```

## ğŸ”§ API

The backend exposes a full REST API at `http://127.0.0.1:8741`:

- `POST /api/chat` â€” Send a message (SSE streaming response)
- `GET /api/conversations` â€” List conversations
- `POST /api/journal/generate` â€” Generate today's journal
- `GET /api/tasks` â€” List tasks
- `GET /api/models` â€” List available GGUF models
- `POST /api/models/load` â€” Load a model
- `GET /api/context/recent` â€” View recent screen context
- `GET /api/settings` â€” View settings

Full interactive docs at **http://127.0.0.1:8741/docs**

## ğŸ”’ Privacy

- **No network requests** â€” all processing is local
- **No telemetry** â€” zero tracking or analytics
- **No cloud** â€” data never leaves your Mac
- **SQLite database** â€” stored in `libre_bird.db`, easy to inspect or delete
- **Open source** â€” you can audit every line of code

## âš™ï¸ Requirements

- macOS with Apple Silicon (M1/M2/M3/M4)
- 16GB RAM (for GPT-OSS 20B Q4)
- Python 3.11+
- Node.js 18+
- ~10GB disk space for the model

## ğŸ“ License

MIT â€” Free for any use.
